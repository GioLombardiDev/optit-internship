{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5145fc2b",
   "metadata": {},
   "source": [
    "# Series analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf661632",
   "metadata": {},
   "source": [
    "## Import libreries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dc37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Detect if running on Google Colab\n",
    "def in_colab():\n",
    "    return importlib.util.find_spec(\"google.colab\") is not None\n",
    "\n",
    "# Set base directory and handle environment\n",
    "if in_colab():\n",
    "    # Install required packages only if not already installed\n",
    "    def install(package):\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "    install(\"utilsforecast\")\n",
    "\n",
    "    # Mount Google Drive\n",
    "    from google.colab import drive  # type: ignore\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Set base directory to your Drive project folder\n",
    "    BASE_DIR = Path('/content/drive/MyDrive/heat-forecast')\n",
    "\n",
    "    # Add `src/` to sys.path for custom package imports\n",
    "    src_path = BASE_DIR / 'src'\n",
    "    if str(src_path) not in sys.path:\n",
    "        sys.path.append(str(src_path))\n",
    "\n",
    "else:\n",
    "    # Local/VM setup: assume notebook is in project_root/notebooks/\n",
    "    BASE_DIR = Path.cwd().parent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415a7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- IPython Magic ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- Standard Library ---\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "# --- Scientific Computing & Data Handling ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "\n",
    "# --- Plotting & Visualization ---\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from cycler import cycler\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "\n",
    "# --- Statistics & Modeling ---\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "\n",
    "# --- Machine Learning & Dimensionality Reduction ---\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- Forecasting & Preprocessing ---\n",
    "from utilsforecast.preprocessing import fill_gaps\n",
    "\n",
    "# --- Custom Modules ---\n",
    "from heat_forecast.utils.plotting import (\n",
    "    configure_time_axes, plot_weekly_seasonality, plot_daily_seasonality,\n",
    "    display_scrollable\n",
    ")\n",
    "from heat_forecast.utils.transforms import make_is_winter\n",
    "\n",
    "# --- Plotting Configuration ---\n",
    "interactive = False  # Set to False for static plots\n",
    "plt.style.use(\"ggplot\")\n",
    "palette = sns.color_palette(\"tab10\", 5)\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,\n",
    "    'axes.titlesize': 16,\n",
    "    'axes.labelsize': 14,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'legend.fontsize': 10,\n",
    "    'figure.titlesize': 18\n",
    "})\n",
    "mpl.rcParams['axes.prop_cycle'] = cycler(color=[\"#000000\", \"#000000\"])\n",
    "mpl.rcParams['axes.grid'] = True\n",
    "mpl.rcParams['axes.grid.which'] = 'both'\n",
    "\n",
    "# --- Logging Configuration ---\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(name)s | %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    force=True,\n",
    "    stream=sys.stdout\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ec5c0d",
   "metadata": {},
   "source": [
    "## Description and visualization of the target series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21edd00b",
   "metadata": {},
   "source": [
    "Import the target series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1382a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_df = pd.DataFrame()\n",
    "for id in range(1, 6):\n",
    "    path = BASE_DIR / \"data\" / \"timeseries\" / f\"impianto{id}\" / f\"impianto{id}_heat_demand.csv\"\n",
    "    df = pd.read_csv(path, sep=';', parse_dates=['timestamp'])\n",
    "    logging.info(f'Processing data for facility {id}')\n",
    "    df.columns = ['ds', 'y']\n",
    "    df['unique_id'] = f'F{id}'\n",
    "    df = fill_gaps(df, freq='h') # fill missing timestamps in ds using nans \n",
    "    heat_df = pd.concat([heat_df, df], ignore_index=True)\n",
    "heat_df['ds'] = heat_df['ds'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c248b",
   "metadata": {},
   "source": [
    "Plot of the target series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(15, 15), sharex=False, sharey=True)\n",
    "for i, (id, group) in enumerate(heat_df.groupby('unique_id')):\n",
    "    sns.lineplot(data=group, x='ds', y='y', ax=axes[i], label=id, color=palette[i])\n",
    "    axes[i].set_title(f'{id}', fontsize=16)\n",
    "\n",
    "configure_time_axes(axes, heat_df['ds'])\n",
    "\n",
    "fig.suptitle('Heat Demand for each id')\n",
    "fig.supxlabel('Date time [H]')\n",
    "fig.supylabel('Heat Demand [kWh]')\n",
    "fig.tight_layout(rect=[0.01, 0.01, 0.99, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b920765",
   "metadata": {},
   "source": [
    "To inspect the time series further, specify a period to zoom in on a specific date range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose plot period\n",
    "period = pd.date_range(start='2023-10-01', end='2024-05-01', freq='h')\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(15, 20), sharey=True)\n",
    "axes = axes.flatten()\n",
    "mask = heat_df['ds'].isin(period)\n",
    "for i, (id, group) in enumerate(heat_df.loc[mask].groupby('unique_id')):\n",
    "    ax = axes[i]\n",
    "    sns.lineplot(data=group, x='ds', y='y', ax=ax, label=id, color=palette[i])\n",
    "    ax.set_title(f'{id}', fontsize=16)\n",
    "\n",
    "configure_time_axes(axes, period)\n",
    "\n",
    "fig.suptitle('Heat Demand for a specified period')\n",
    "fig.supxlabel('Date')\n",
    "fig.supylabel('Heat Demand [kWh]')\n",
    "fig.tight_layout(rect=[0.01, 0.01, 0.99, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35be7a6e",
   "metadata": {},
   "source": [
    "Show basic dataset summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a893df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(df, name, target_col='y', zero_count=True):\n",
    "    logging.info(f\"\\nBasic series information: {name}\")\n",
    "\n",
    "    agg_dict = {\n",
    "        \"count\": (target_col, \"count\"),\n",
    "        \"mean\": (target_col, \"mean\"),\n",
    "        \"std\": (target_col, \"std\"),\n",
    "        \"min\": (target_col, \"min\"),\n",
    "        \"p05\": (target_col, lambda x: x.quantile(0.05)),\n",
    "        \"p25\": (target_col, lambda x: x.quantile(0.25)),\n",
    "        \"p50\": (target_col, lambda x: x.quantile(0.50)),\n",
    "        \"p75\": (target_col, lambda x: x.quantile(0.75)),\n",
    "        \"p95\": (target_col, lambda x: x.quantile(0.95)),\n",
    "        \"max\": (target_col, \"max\"),\n",
    "        \"missing_count\": (target_col, lambda x: x.isna().sum()),\n",
    "        \"start\": (\"ds\", \"min\"),\n",
    "        \"end\": (\"ds\", \"max\"),\n",
    "    }\n",
    "\n",
    "    if zero_count:\n",
    "        agg_dict[\"zero_count\"] = (target_col, lambda x: (x == 0).sum())\n",
    "\n",
    "    summary = df.groupby(\"unique_id\").agg(**agg_dict)\n",
    "    display(summary)\n",
    "\n",
    "# Full year\n",
    "summarize(heat_df, \"all year\")\n",
    "\n",
    "# Cold semester (Nov–Apr)\n",
    "cold_months = [11, 12, 1, 2, 3, 4]\n",
    "heat_cold_df = heat_df[heat_df['ds'].dt.month.isin(cold_months)]\n",
    "summarize(heat_cold_df, \"coldest semester (Nov-Apr)\")\n",
    "\n",
    "# Warm semester (May–Oct)\n",
    "warm_months = [5, 6, 7, 8, 9, 10]\n",
    "heat_warm_df = heat_df[heat_df['ds'].dt.month.isin(warm_months)]\n",
    "summarize(heat_warm_df, \"warmest semester (May-Oct)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f80be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clip values below 5 kWh \n",
    "min_threshold = 5.0\n",
    "\n",
    "# Count values below the threshold\n",
    "low_values_by_facility = heat_df[heat_df['y'] < min_threshold].groupby('unique_id')['y'].agg(low_count='count').T\n",
    "total_count = len(heat_df[heat_df['y'] < min_threshold])\n",
    "low_values_by_facility['total'] = total_count\n",
    "logging.info(\"Low values by facility:\")\n",
    "display(low_values_by_facility)\n",
    "\n",
    "# Apply the capping\n",
    "heat_df_capped = heat_df.copy()\n",
    "heat_df_capped.loc[heat_df_capped['y'] < min_threshold, 'y'] = min_threshold\n",
    "\n",
    "# Update heat_df with the capped values\n",
    "heat_df = heat_df_capped.copy()\n",
    "logging.info(\"Capping applied.\")\n",
    "\n",
    "# Verify the capping worked\n",
    "low_values_by_facility = heat_df[heat_df['y'] < min_threshold].groupby('unique_id')['y'].agg(low_count='count').T\n",
    "total_count = len(heat_df[heat_df['y'] < min_threshold])\n",
    "low_values_by_facility['total'] = total_count\n",
    "logging.info(\"Sanity check, low values by facility:\")\n",
    "display(low_values_by_facility)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af406ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat demand grouped by month (whose number is shown on the right side of the plot) for the coldest months\n",
    "lam = plot_weekly_seasonality(heat_df, only_cold_months=True, make_is_winter=make_is_winter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745654e1",
   "metadata": {},
   "source": [
    "The function `plot_daily_seasonality` below is analogous to the previous one, but it displays daily load profiles instead of weekly patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat demand grouped by month (whose number is shown on the right side of the plot) for the coldest months\n",
    "lam = plot_daily_seasonality(heat_df, only_cold_months=True, make_is_winter=make_is_winter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ff46f",
   "metadata": {},
   "source": [
    "A closer examination of the weekly seasonal patterns reveals that F2 is the only series without a clear weekly structure, while F3 and F5 exhibit the most pronounced weekly seasonality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c17f74",
   "metadata": {},
   "source": [
    "### Plot of aggregated y series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658182c",
   "metadata": {},
   "source": [
    "Aggregate the series to the daily level by averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf92774",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_daily_df = (\n",
    "    heat_df\n",
    "    .groupby('unique_id')\n",
    "    .resample('D', on='ds', include_groups=False)\n",
    "    .mean(numeric_only=True)   # average numeric columns\n",
    "    .reset_index()             # bring ds and unique_id back as columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d304dd89",
   "metadata": {},
   "source": [
    "Plot of the daily-aggregated target series across all years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(15, 15), sharex=False, sharey=True)\n",
    "for i, (id, group) in enumerate(heat_daily_df.groupby('unique_id')):\n",
    "    sns.lineplot(data=group, x='ds', y='y', ax=axes[i], label=id, color=palette[i])\n",
    "    axes[i].set_title(f'{id}', fontsize=16)\n",
    "\n",
    "configure_time_axes(axes, heat_daily_df['ds'])\n",
    "\n",
    "fig.suptitle('Heat Demand for each id')\n",
    "fig.supxlabel('Date [D]')\n",
    "fig.supylabel('Heat Demand [kWh]')\n",
    "fig.tight_layout(rect=[0.01, 0.01, 0.99, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b77742e",
   "metadata": {},
   "source": [
    "Plot of the aggregated target series over a specified time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bd728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose plot period\n",
    "period = pd.date_range(start='2023-10-01', end='2024-06-01', freq='h')\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(nrows=5, ncols=1, figsize=(15, 20), sharey=True)\n",
    "axes = axes.flatten()\n",
    "mask = heat_daily_df['ds'].isin(period)\n",
    "for i, (id, group) in enumerate(heat_daily_df.loc[mask].groupby('unique_id')):\n",
    "    ax = axes[i]\n",
    "    sns.lineplot(data=group, x='ds', y='y', ax=ax, label=id, color=palette[i])\n",
    "    ax.set_title(f'{id}')\n",
    "\n",
    "configure_time_axes(axes, period)\n",
    "\n",
    "fig.suptitle('Heat Demand for a specified period')\n",
    "fig.supxlabel('Date')\n",
    "fig.supylabel('Heat Demand [kWh]')\n",
    "fig.tight_layout(rect=[0.01, 0.01, 0.99, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5828dbc7",
   "metadata": {},
   "source": [
    "This confirms the earlier observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603ca59a",
   "metadata": {},
   "source": [
    "## Import and plot the auxiliary series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05100e32",
   "metadata": {},
   "source": [
    "Import the target series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7cd9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_df = pd.DataFrame()\n",
    "for id in range(1, 6):\n",
    "    path = BASE_DIR / \"data\" / \"timeseries\" / f\"impianto{id}\" / f\"impianto{id}_auxiliary_series.csv\"\n",
    "    df = pd.read_csv(path, sep=';', parse_dates=['time'])\n",
    "    logging.info(f'Processing auxiliary data for facility {id}')\n",
    "    df.rename(columns={'time': 'ds'}, inplace=True)\n",
    "    df['unique_id'] = f'F{id}'\n",
    "    df = fill_gaps(df, freq='h') # fill missing timestamps in ds using nans \n",
    "    aux_df = pd.concat([aux_df, df], ignore_index=True)\n",
    "aux_df['ds'] = aux_df['ds'].dt.tz_localize(None)\n",
    "aux_cols = aux_df.columns.difference(['ds', 'unique_id']).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e79a70",
   "metadata": {},
   "source": [
    "Plot auxiliary and target series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1919048",
   "metadata": {},
   "outputs": [],
   "source": [
    "units = {\n",
    "    'dew_point': '°C',  \n",
    "    'humidity': '%',\n",
    "    'pressure': 'hPa',\n",
    "    'temperature': '°C',\n",
    "    'wind_speed': 'm/s'\n",
    "} # Probable units for the auxiliary series\n",
    "\n",
    "# Select only common timestamps for alignment in the plot\n",
    "common_ds = heat_df['ds'].isin(aux_df['ds'])\n",
    "heat_df_filtered = heat_df[common_ds]\n",
    "aux_df_filtered = aux_df[aux_df['ds'].isin(heat_df_filtered['ds'])]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(12, 16))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot the target series\n",
    "ax = axes[0]\n",
    "sns.lineplot(data=heat_df_filtered.pivot(index='ds', columns='unique_id', values='y'), ax=ax, palette=palette, alpha=0.7, dashes=False)\n",
    "ax.set_title('Heat Demand [kWh]')\n",
    "ax.legend(title='Facility ID')\n",
    "\n",
    "# Plot the auxiliary series\n",
    "for i, c in enumerate(aux_cols):\n",
    "    ax = axes[i + 1]  # Skip the first axis for the target series\n",
    "    col_df = aux_df_filtered.loc[:, ['ds', 'unique_id', c]]\n",
    "    col_df = col_df.pivot(index='ds', columns='unique_id', values=c)\n",
    "    sns.lineplot(data=col_df, ax=ax, palette=palette, alpha=0.7, dashes=False)\n",
    "    ax.set_title(f'{c} [{units[c]}]')\n",
    "    ax.legend(title='Facility ID')\n",
    "\n",
    "configure_time_axes(axes, aux_df_filtered['ds'], global_legend=True, legend_fig=fig)\n",
    "\n",
    "fig.suptitle('Auxiliary and Target Series')\n",
    "fig.supxlabel('Date and Time [H]')\n",
    "fig.tight_layout(rect=[0.01, 0.02, 0.99, 0.98])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d6165c",
   "metadata": {},
   "source": [
    "Let's again compare visually, only for a given period and daily aggregated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d57384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the auxiliary series to daily frequency\n",
    "aux_daily_df = (\n",
    "    aux_df\n",
    "    .groupby('unique_id')\n",
    "    .resample('D', on='ds', include_groups=False)\n",
    "    .mean(numeric_only=True)   # average numeric columns\n",
    "    .reset_index()             # bring ds and unique_id back as columns\n",
    ")\n",
    "\n",
    "# Choose plot period\n",
    "period = pd.date_range(start='2023-10-01', end='2024-06-01', freq='h')\n",
    "\n",
    "fig, axes = plt.subplots(nrows=6, ncols=1, figsize=(15, 22))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot the target series\n",
    "ax = axes[0]\n",
    "heat_daily_period_df = heat_daily_df[heat_daily_df['ds'].isin(period)]\n",
    "sns.lineplot(data=heat_daily_period_df.pivot(index='ds', columns='unique_id', values='y'), ax=ax, palette=palette, alpha=0.7, dashes=False)\n",
    "ax.set_title('Heat Demand [kWh]')\n",
    "ax.legend(title='Facility ID')\n",
    "\n",
    "# Plot the auxiliary series\n",
    "aux_daily_period_df = aux_daily_df[aux_daily_df['ds'].isin(period)]\n",
    "for i, c in enumerate(aux_cols):\n",
    "    ax = axes[i + 1]  # Skip the first axis for the target series\n",
    "    col_df = aux_daily_period_df.loc[:, ['ds', 'unique_id', c]]\n",
    "    col_df = col_df.pivot(index='ds', columns='unique_id', values=c)\n",
    "    sns.lineplot(data=col_df, ax=ax, palette=palette, alpha=0.7, dashes=False)\n",
    "    ax.set_title(f'{c} [{units[c]}]')\n",
    "    ax.legend(title='Facility ID')\n",
    "\n",
    "configure_time_axes(axes, aux_daily_period_df['ds'], global_legend=True, legend_fig=fig)\n",
    "\n",
    "fig.suptitle('Auxiliary and Target Series')\n",
    "fig.supxlabel('Date [D]')\n",
    "fig.tight_layout(rect=[0.01, 0.02, 0.99, 0.98])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2569a286",
   "metadata": {},
   "source": [
    "Summary per series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in aux_cols:\n",
    "    summarize(aux_df[['ds', 'unique_id', col]], f\"auxiliary column '{col}'\", target_col=col, zero_count=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e669e30",
   "metadata": {},
   "source": [
    "## Study of the correlation between exog variables for a single ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ddffc",
   "metadata": {},
   "source": [
    "We will analyze the correlation between variables both at the individual ID level and using daily aggregated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e72e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a specific facility ID for correlation analysis\n",
    "facility_id = 'F4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21057f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the specific facility ID\n",
    "heat_facility_daily_df = heat_daily_df[heat_daily_df['unique_id'] == facility_id].copy().reset_index(drop=True)\n",
    "heat_facility_daily_df = heat_facility_daily_df[heat_facility_daily_df['ds'] < pd.Timestamp('2024-06-01')]\n",
    "aux_facility_daily_df = aux_daily_df[aux_daily_df['unique_id'] == facility_id].copy().reset_index(drop=True)\n",
    "aux_facility_daily_df = aux_facility_daily_df[aux_facility_daily_df['ds'] < pd.Timestamp('2024-06-01')]\n",
    "\n",
    "# Merge\n",
    "facility_daily_df = heat_facility_daily_df.merge(aux_facility_daily_df, on=['ds', 'unique_id'], how='inner')\n",
    "\n",
    "# Select numeric columns\n",
    "df_for_plot = facility_daily_df.select_dtypes(include='number')\n",
    "\n",
    "# Define custom correlation annotation for upper plot\n",
    "def corrfunc(x, y, **kws):\n",
    "    pearson_r, _ = pearsonr(x, y)\n",
    "    spearman_r, _ = spearmanr(x, y)\n",
    "    kendall_r, _ = kendalltau(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\n",
    "        f\"P: {pearson_r:.2f}\\n\"\n",
    "        f\"S: {spearman_r:.2f}\\n\"\n",
    "        f\"K: {kendall_r:.2f}\",\n",
    "        xy=(0.5, 0.5),\n",
    "        xycoords=\"axes fraction\",\n",
    "        ha=\"center\", va=\"center\",\n",
    "        fontsize=10\n",
    "    )\n",
    "\n",
    "# Define custom scatterplot with trendlines\n",
    "def scatter_with_trend(x, y, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    sns.scatterplot(x=x, y=y, ax=ax, s=10, alpha=0.6)\n",
    "    sns.regplot(x=x, y=y, ax=ax, scatter=False, color='black', ci=None)  # Linear trend\n",
    "    smoothed = sm.nonparametric.lowess(y, x, frac=0.3)\n",
    "    ax.plot(smoothed[:, 0], smoothed[:, 1], color='red', linestyle='--')  # LOWESS\n",
    "'''\n",
    "# 7. PairGrid plot\n",
    "g = sns.PairGrid(df_for_plot, height=2.0)\n",
    "g.map_lower(scatter_with_trend)\n",
    "g.map_upper(corrfunc)\n",
    "g.map_diag(sns.histplot, kde=True)\n",
    "\n",
    "# Adjust labels and titles\n",
    "g.set(xlabel=\"\")\n",
    "for i, col in enumerate(df_for_plot.columns):\n",
    "    g.axes[0, i].set_title(col, fontsize=12)\n",
    "\n",
    "plt.suptitle(f'Correlation & Trend Analysis for Facility {facility_id} (Daily)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965aa350",
   "metadata": {},
   "source": [
    "Since our main focus is on the cold season, let's generate the same plot using only data from that period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b44d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for the specific facility ID and cold months\n",
    "heat_facility_winter_daily_df = (\n",
    "    heat_facility_daily_df\n",
    "    .loc[heat_daily_df['ds'].dt.month.isin([11, 12, 1, 2, 3])]\n",
    ")\n",
    "aux_facility_winter_daily_df = (\n",
    "    aux_facility_daily_df\n",
    "    .loc[aux_daily_df['ds'].dt.month.isin([11, 12, 1, 2, 3])]\n",
    ")\n",
    "\n",
    "# Merge\n",
    "facility_winter_daily_df = heat_facility_winter_daily_df.merge(aux_facility_winter_daily_df, on=['ds', 'unique_id'], how='inner')\n",
    "\n",
    "# Select numeric columns\n",
    "df_for_plot = facility_winter_daily_df.select_dtypes(include='number')\n",
    "\n",
    "# PairGrid plot\n",
    "g = sns.PairGrid(df_for_plot, height=2.0)\n",
    "g.map_lower(scatter_with_trend)\n",
    "g.map_upper(corrfunc)\n",
    "g.map_diag(sns.histplot, kde=True)\n",
    "\n",
    "# Adjust labels and titles\n",
    "g.set(xlabel=\"\")\n",
    "for i, col in enumerate(df_for_plot.columns):\n",
    "    g.axes[0, i].set_title(col, fontsize=12)\n",
    "\n",
    "plt.suptitle(f'Correlation & Trend Analysis for Facility {facility_id} and winter period only (Daily)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the heat and auxiliary dataframes for the specific facility ID\n",
    "heat_facility_df = heat_df[heat_df['unique_id'] == facility_id].copy().reset_index(drop=True)\n",
    "aux_facility_df = aux_df[aux_df['unique_id'] == facility_id].copy().reset_index(drop=True)\n",
    "\n",
    "# Filter for the winter period\n",
    "heat_facility_winter_df = (\n",
    "    heat_facility_df\n",
    "    .loc[heat_facility_df['ds'].dt.month.isin([11, 12, 1, 2, 3]) & heat_facility_df['ds'].dt.year] #.isin([2022, 2023])] \n",
    ")\n",
    "aux_facility_winter_df = (\n",
    "    aux_facility_df\n",
    "    .loc[aux_facility_df['ds'].dt.month.isin([11, 12, 1, 2, 3]) & aux_facility_df['ds'].dt.year] #.isin([2022, 2023])] \n",
    ")\n",
    "\n",
    "# Merge\n",
    "facility_winter_df = heat_facility_winter_df.merge(aux_facility_winter_df, on=['ds', 'unique_id'], how='inner')\n",
    "\n",
    "# Select numeric columns\n",
    "df_for_plot = facility_winter_df.select_dtypes(include='number')\n",
    "\n",
    "# PairGrid plot\n",
    "g = sns.PairGrid(df_for_plot, height=2.0)\n",
    "g.map_lower(scatter_with_trend)\n",
    "g.map_upper(corrfunc)\n",
    "g.map_diag(sns.histplot, kde=True)\n",
    "\n",
    "# Adjust labels and titles\n",
    "g.set(xlabel=\"\")\n",
    "for i, col in enumerate(df_for_plot.columns):\n",
    "    g.axes[0, i].set_title(col, fontsize=12)\n",
    "\n",
    "plt.suptitle(f'Correlation & Trend Analysis for Facility {facility_id} and winter period only (Hourly)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41d0cef",
   "metadata": {},
   "source": [
    "## Anomaly detection using DPCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1945b509",
   "metadata": {},
   "source": [
    "We now apply DPCA for anomaly detection, again at the individual ID level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e618bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a specific facility ID for correlation analysis\n",
    "facility_id = 'F1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd424682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the heat and auxiliary daily dataframes for the specific facility ID\n",
    "heat_facility_df = heat_df[heat_df['unique_id'] == facility_id].copy().reset_index(drop=True)\n",
    "aux_facility_df = aux_df[aux_df['unique_id'] == facility_id].copy().reset_index(drop=True)\n",
    "facility_df = heat_facility_df.merge(aux_facility_df, on=['ds', 'unique_id'], how='inner')\n",
    "\n",
    "# Build a dict of Series for every lagged column\n",
    "numeric_cols = facility_df.select_dtypes(include='number').columns.tolist()\n",
    "max_lag = 5  # Maximum lag to consider\n",
    "lags = np.arange(1, max_lag + 1)  # Define lags\n",
    "lagged = {\n",
    "    f\"{c}_lag_{lag}\": facility_df[c].shift(lag)\n",
    "    for c in numeric_cols\n",
    "    for lag in lags\n",
    "}\n",
    "\n",
    "# Turn it into a DataFrame and concatenate with the original DataFrame\n",
    "lagged_df = pd.DataFrame(lagged)\n",
    "facility_wlags_df = pd.concat([facility_df, lagged_df], axis=1)\n",
    "facility_wlags_df.dropna(inplace=True)  # Drop rows with NaN values (due to lags)\n",
    "facility_wlags_df.reset_index(inplace=True, drop=True)  # Reset index after dropping rows\n",
    "\n",
    "# Delete non-numeric columns for DPCA\n",
    "ds = facility_wlags_df['ds'] # Save the 'ds' column to re-add it later\n",
    "facility_wlags_df.drop(columns=['ds', 'unique_id'], inplace=True)  # Drop 'ds' and 'unique_id' for DPCA\n",
    "logging.info(\"Endogenous and exogenous variables with their lags, for DPCA:\")\n",
    "display(facility_wlags_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e699adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data before PCA\n",
    "scaler = StandardScaler()\n",
    "Z = scaler.fit_transform(facility_wlags_df)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "Z_pca = pca.fit_transform(Z)\n",
    "\n",
    "# Create a DataFrame with PCA results\n",
    "pca_df = pd.DataFrame(Z_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['ds'] = ds.values  # Re-add the 'ds' column\n",
    "pca_df['index'] = np.arange(len(pca_df))  # Add the unique_id column back\n",
    "pca_df['month'] = ds.dt.month\n",
    "pca_df['quarter'] = ds.dt.quarter\n",
    "pca_df['hour'] = ds.dt.hour\n",
    "pca_df['dayofyear'] = ds.dt.dayofyear\n",
    "\n",
    "# Plot the PCA results\n",
    "if interactive:\n",
    "    fig = px.scatter(\n",
    "        pca_df,\n",
    "        x=\"PC1\",\n",
    "        y=\"PC2\",\n",
    "        color='month',\n",
    "        hover_data=[\"ds\"],\n",
    "        opacity=0.7, \n",
    "        title=f\"DPCA on {facility_id} using {max_lag} lags\",\n",
    "        width=800,   # in pixels\n",
    "        height=600   \n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "else:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(\n",
    "        pca_df['PC1'],\n",
    "        pca_df['PC2'],\n",
    "        c=pca_df['month'],\n",
    "        s=20,\n",
    "        cmap='tab10',\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    plt.colorbar(scatter, label='Month')\n",
    "    plt.title(f\"DPCA on {facility_id} using {max_lag} lags\")\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043104d8",
   "metadata": {},
   "source": [
    "By examining the plot using the two principal components, incorporating both 0 and 5 lags of the variables, we observe some data points that deviate from the general pattern. To determine whether these are genuine outliers, we'll visualize them in the original space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb88d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "match facility_id:\n",
    "    case 'F1':\n",
    "        possible_outliers_0lags = ['2023-02-26T07:00:00', '2019-12-22T11:00:00']\n",
    "        possible_outliers_5lags = ['2019-12-22T10:00:00']\n",
    "    case 'F2':\n",
    "        possible_outliers_5lags = ['2022-01-13T08:00:00', '2022-01-13T09:00:00',  '2022-01-13T10:00:00'] \\\n",
    "            + ['2021-02-13T12:00:00', '2021-02-13T13:00:00', '2021-02-13T14:00:00'] \\\n",
    "            + ['2024-04-16T15:00:00', '2024-04-16T16:00:00', '2024-04-16T17:00:00', '2024-04-16T18:00:00'] \n",
    "        possible_outliers_0lags = ['2020-07-24T06:00:00', '2022-02-07T11:00:00']\n",
    "    case 'F3':\n",
    "        possible_outliers_0lags = ['2020-02-04T14:00:00', '2024-08-27T13:00:00']\n",
    "        possible_outliers_5lags = []\n",
    "    case 'F4':\n",
    "        possible_outliers_0lags = ['2020-11-22T21:00:00', '2020-02-04T16:00:00', '2020-06-29T14:00:00']\n",
    "        possible_outliers_5lags = ['2019-12-13T18:00:00', '2019-12-13T19:00:00', '2019-12-13T20:00:00', '2019-12-13T21:00:00'] \\\n",
    "            + ['2022-11-22T18:00:00', '2022-11-22T19:00:00', '2022-11-22T20:00:00'] \\\n",
    "            + ['2023-11-03T10:00:00', '2023-11-03T11:00:00', '2023-11-03T12:00:00']\n",
    "    case 'F5':\n",
    "        possible_outliers_0lags = ['2019-12-13T15:00:00', '2020-02-04T16:00:00', '2020-02-04T13:00:00', '2020-06-29T14:00:00', '2023-02-10T07:00:00']\n",
    "        possible_outliers_5lags = ['2019-12-13T18:00:00', '2019-12-13T19:00:00', '2019-12-13T20:00:00', '2019-12-13T21:00:00'] \\\n",
    "            + ['2022-11-22T18:00:00', '2022-11-22T19:00:00', '2022-11-22T20:00:00'] \\\n",
    "            + ['2023-11-03T10:00:00', '2023-11-03T11:00:00', '2023-11-03T12:00:00']\n",
    "possible_outliers = possible_outliers_5lags + possible_outliers_0lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d833b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse strings into datetimes, then filter\n",
    "possible_outliers_ds = [pd.to_datetime(d) for d in possible_outliers]\n",
    "possible_outliers_df = facility_df[facility_df['ds'].isin(possible_outliers_ds)]\n",
    "\n",
    "# columns and their units\n",
    "col = ['y', 'dew_point', 'temperature', 'pressure', 'wind_speed', 'humidity']\n",
    "units = ['kWh', '°C', 'hPa', '°C', 'm/s', '%']\n",
    "units_map = dict(zip(col, units))\n",
    "\n",
    "# prepare DataFrames\n",
    "df_for_plot = facility_df.drop(columns=['unique_id']).set_index('ds')\n",
    "df_outliers_for_plot = possible_outliers_df.drop(columns=['unique_id']).set_index('ds')\n",
    "\n",
    "# Plot\n",
    "if interactive:\n",
    "    # build subplots\n",
    "    fig = make_subplots(\n",
    "        rows=len(col), cols=1,\n",
    "        shared_xaxes=False,\n",
    "        subplot_titles=[f\"{c} [{units_map[c]}]\" for c in col],\n",
    "        row_heights=[1]*len(col),  \n",
    "        vertical_spacing=0.04   \n",
    "    )\n",
    "\n",
    "    # add traces\n",
    "    for i, c in enumerate(col, start=1):\n",
    "        # full series (no hover)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_for_plot.index,\n",
    "                y=df_for_plot[c],\n",
    "                mode=\"lines\",\n",
    "                line=dict(color=\"black\"),\n",
    "                showlegend=False,\n",
    "                hoverinfo='skip'\n",
    "            ),\n",
    "            row=i, col=1\n",
    "        )\n",
    "        # outlier markers (interactive)\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_outliers_for_plot.index,\n",
    "                y=df_outliers_for_plot[c],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(color=\"red\", size=8),\n",
    "                name=\"outlier\",\n",
    "                showlegend=False,\n",
    "                hovertemplate=\"Date: %{x|%Y-%m-%d %H:%M}<br>Value: %{y}<extra></extra>\"\n",
    "            ),\n",
    "            row=i, col=1\n",
    "        )\n",
    "\n",
    "    # layout\n",
    "    fig.update_layout(\n",
    "        height=220 * len(col),\n",
    "        title_text=f\"All Series and red-colored Possible Outliers - Facility {facility_id[-1]}\",\n",
    "    )\n",
    "    fig.add_annotation(\n",
    "        text=\"Year\",\n",
    "        x=0.5, y=-0.03,\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=14)\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "else:\n",
    "    n_rows = len(col)\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=n_rows,\n",
    "        ncols=1,\n",
    "        figsize=(12, 2.5 * n_rows),  # Adjust width/height as needed\n",
    "        sharex=False\n",
    "    )\n",
    "\n",
    "    # Ensure axes is always iterable (even if n_rows=1)\n",
    "    if n_rows == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Plot each variable\n",
    "    for i, (ax, c) in enumerate(zip(axes, col)):\n",
    "        # Plot full series\n",
    "        ax.plot(\n",
    "            df_for_plot.index,\n",
    "            df_for_plot[c],\n",
    "            color=\"black\",\n",
    "            label=\"Value\"\n",
    "        )\n",
    "        \n",
    "        # Plot outliers\n",
    "        ax.scatter(\n",
    "            df_outliers_for_plot.index,\n",
    "            df_outliers_for_plot[c],\n",
    "            color=\"red\",\n",
    "            s=40,\n",
    "            label=\"Outlier\",\n",
    "            zorder=5\n",
    "        )\n",
    "\n",
    "        # Title and y-label\n",
    "        ax.set_title(f\"{c} [{units_map[c]}]\", fontsize=12)\n",
    "        ax.set_ylabel(units_map[c], fontsize=10)\n",
    "\n",
    "        # Improve layout\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Common X-label \n",
    "    fig.text(0.5, 0.01, \"Date\", ha=\"center\", fontsize=14)\n",
    "\n",
    "    # --- Main Title ---\n",
    "    fig.suptitle(\n",
    "        f\"All Series and Red-Colored Possible Outliers - Facility {facility_id[-1]}\",\n",
    "        fontsize=16\n",
    "    )\n",
    "\n",
    "    plt.tight_layout() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13efc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_adjust = {\n",
    "    'F2': ['2020-07-24T06:00:00']\n",
    "}\n",
    "\n",
    "# parse strings to datetimes\n",
    "to_adjust = {uid: [pd.to_datetime(dt) for dt in dts] for uid, dts in to_adjust.items()}\n",
    "\n",
    "# forward‐fill in heat_df\n",
    "for uid, dts in to_adjust.items():\n",
    "    for dt in dts:\n",
    "        mask = (heat_df['unique_id'] == uid) & (heat_df['ds'] == dt)\n",
    "        # set the target to NaN\n",
    "        logging.info(\"Target observations before adjustment:\")\n",
    "        display(heat_df[mask])\n",
    "        heat_df.loc[mask, 'y'] = np.nan\n",
    "# ensure ordering, then ffill per facility\n",
    "heat_df.sort_values(['unique_id', 'ds'], inplace=True)\n",
    "heat_df['y'] = heat_df.groupby('unique_id')['y'].ffill()\n",
    "logging.info(\"Target observations after adjustment:\")\n",
    "display(heat_df[mask])\n",
    "\n",
    "# 2) forward‐fill in aux_df\n",
    "aux_cols = aux_df.columns.difference(['ds', 'unique_id'])\n",
    "for uid, dts in to_adjust.items():\n",
    "    for dt in dts:\n",
    "        mask = (aux_df['unique_id'] == uid) & (aux_df['ds'] == dt)\n",
    "        logging.info(\"Auxiliary observations before adjustment:\")\n",
    "        display(aux_df[mask])\n",
    "        # set all auxiliary columns to NaN\n",
    "        aux_df.loc[mask, aux_cols] = np.nan\n",
    "# ensure ordering, then ffill per facility\n",
    "aux_df.sort_values(['unique_id', 'ds'], inplace=True)\n",
    "aux_df[aux_cols] = aux_df.groupby('unique_id')[aux_cols].ffill()\n",
    "logging.info(\"Auxiliary observations after adjustment:\")\n",
    "display(aux_df[mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a681f9a",
   "metadata": {},
   "source": [
    "## Save elaborated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a587045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_heat = BASE_DIR / \"data\" / \"timeseries_preprocessed\" / \"heat.csv\"\n",
    "heat_df.to_csv(path_heat, index=False, encoding=\"utf-8\")\n",
    "logging.info(\"Heat demand data saved to {}\".format(path_heat.relative_to(BASE_DIR)))\n",
    "\n",
    "path_aux = BASE_DIR / \"data\" / \"timeseries_preprocessed\" / \"auxiliary.csv\"\n",
    "aux_df.to_csv(path_aux, index=False, encoding=\"utf-8\")\n",
    "logging.info(\"Auxiliary data saved to {}\".format(path_aux.relative_to(BASE_DIR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d772af09",
   "metadata": {},
   "source": [
    "## Thesis figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c29d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "heat_df = pd.DataFrame()\n",
    "for id in range(1, 6):\n",
    "    path = BASE_DIR / \"data\" / \"timeseries\" / f\"impianto{id}\" / f\"impianto{id}_heat_demand.csv\"\n",
    "    df = pd.read_csv(path, sep=';', parse_dates=['timestamp'])\n",
    "    logging.info(f'Processing data for facility {id}')\n",
    "    df.columns = ['ds', 'y']\n",
    "    df['unique_id'] = f'F{id}'\n",
    "    df = fill_gaps(df, freq='h') # fill missing timestamps in ds using nans \n",
    "    heat_df = pd.concat([heat_df, df], ignore_index=True)\n",
    "heat_df['ds'] = heat_df['ds'].dt.tz_localize(None)\n",
    "unique_ids = heat_df['unique_id'].unique()\n",
    "n_ids = len(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b2990",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=n_ids,\n",
    "    cols=1,\n",
    "    shared_xaxes=False,\n",
    "    shared_yaxes=True,\n",
    "    vertical_spacing=0.06,\n",
    "    subplot_titles=[f\"Series {uid}\" for uid in unique_ids]\n",
    ")\n",
    "for i, uid in enumerate(unique_ids, start=1):\n",
    "    group = heat_df[(heat_df['unique_id'] == uid)]\n",
    "    group = group[(group['ds']>pd.Timestamp('2023-09-15')) & (group['ds']<pd.Timestamp('2024-06-15'))]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=group['ds'],\n",
    "            y=group['y'],\n",
    "            mode='lines',\n",
    "            name=str(uid),\n",
    "            line=dict(color='black')\n",
    "        ),\n",
    "        row=i,\n",
    "        col=1,\n",
    "    )\n",
    "for i in range(1, n_ids + 1):\n",
    "    fig.update_xaxes(\n",
    "        showline=True,\n",
    "        linewidth=1,\n",
    "        linecolor=\"lightgrey\",\n",
    "        mirror=True,\n",
    "        row=i,\n",
    "        col=1\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        showline=True,\n",
    "        linewidth=1,\n",
    "        linecolor=\"lightgrey\",\n",
    "        mirror=True,\n",
    "        row=i,\n",
    "        col=1,\n",
    "        dtick=200\n",
    "    )\n",
    "fig.update_layout(\n",
    "    height=200 * n_ids,\n",
    "    width=750,\n",
    "    title_text=None,\n",
    "    showlegend=False,\n",
    "    margin=dict(l=60, r=20, t=30, b=60),\n",
    ")\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.update_xaxes(title_text=\"Date time\", row=n_ids, col=1)\n",
    "fig.update_yaxes(title_text=\"Heat Demand (kWh)\", row=3, col=1)\n",
    "pio.write_html(\n",
    "    fig, \"fig.html\",\n",
    "    include_plotlyjs=\"inline\", full_html=True,\n",
    "    config={\"toImageButtonOptions\": {\"format\": \"svg\"}}\n",
    ")\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d3e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=n_ids,\n",
    "    cols=1,\n",
    "    shared_xaxes=False,\n",
    "    shared_yaxes=True,\n",
    "    vertical_spacing=0.06,\n",
    "    subplot_titles=[f\"Series {uid}\" for uid in unique_ids]\n",
    ")\n",
    "for i, uid in enumerate(unique_ids, start=1):\n",
    "    group = heat_df[(heat_df['unique_id'] == uid)]\n",
    "    group = group[(group['ds']>=pd.Timestamp('2024-01-01')) & (group['ds']<pd.Timestamp('2024-02-12'))]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=group['ds'],\n",
    "            y=group['y'],\n",
    "            mode='lines',\n",
    "            name=str(uid),\n",
    "            line=dict(color='black')\n",
    "        ),\n",
    "        row=i,\n",
    "        col=1,\n",
    "    )\n",
    "for i in range(1, n_ids + 1):\n",
    "    fig.update_xaxes(\n",
    "        tickformat=\"%b %d\",\n",
    "        showline=True,\n",
    "        linewidth=1,\n",
    "        linecolor=\"lightgrey\",\n",
    "        mirror=True,\n",
    "        row=i,\n",
    "        col=1\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        showline=True,\n",
    "        linewidth=1,\n",
    "        linecolor=\"lightgrey\",\n",
    "        mirror=True,\n",
    "        row=i,\n",
    "        col=1\n",
    "    )\n",
    "fig.update_layout(\n",
    "    height=200 * n_ids,\n",
    "    width=750,\n",
    "    title_text=None,\n",
    "    showlegend=False,\n",
    "    margin=dict(l=60, r=20, t=30, b=60),\n",
    ")\n",
    "fig.update_layout(template='plotly_white')\n",
    "fig.update_xaxes(title_text=\"Date time\", row=n_ids, col=1)\n",
    "fig.update_yaxes(title_text=\"Heat Demand (kWh)\", row=3, col=1)\n",
    "pio.write_html(\n",
    "    fig, \"fig.html\",\n",
    "    include_plotlyjs=\"inline\", full_html=True,\n",
    "    config={\"toImageButtonOptions\": {\"format\": \"svg\"}}\n",
    ")\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf44927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heat_forecast.utils.plotting import plotly_weekly_seasonality\n",
    "\n",
    "groups = [\n",
    "    (pd.Timestamp('2023-09-20'), pd.Timestamp('2024-12-21')),  # autumn\n",
    "    (pd.Timestamp('2024-12-21'), pd.Timestamp('2025-03-21')),  # winter\n",
    "    (pd.Timestamp('2025-03-21'), pd.Timestamp('2025-06-21')),  # spring\n",
    "]\n",
    "\n",
    "labels = [\"Autumn\", \"Winter\", \"Spring\"]\n",
    "\n",
    "fig = plotly_weekly_seasonality(\n",
    "    target_df=heat_df,\n",
    "    groups=groups,\n",
    "    group_labels=labels,\n",
    "    width=750,\n",
    "    height_per_id=300,\n",
    "    vertical_spacing=0.05,\n",
    "    n_cols=1,\n",
    "    annotate=False,\n",
    ")\n",
    "fig.update_layout(\n",
    "    height=210 * n_ids,\n",
    "    width=750,\n",
    "    title_text=None,\n",
    "    showlegend=True,\n",
    "    margin=dict(l=60, r=20, t=30, b=60),\n",
    ")\n",
    "pio.write_html(\n",
    "    fig, \"fig.html\",\n",
    "    include_plotlyjs=\"inline\", full_html=True,\n",
    "    config={\"toImageButtonOptions\": {\"format\": \"svg\"}}\n",
    ")\n",
    "fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "facility_id = 'F1'\n",
    "\n",
    "heat_facility_daily_df = (\n",
    "    heat_daily_df[heat_daily_df['unique_id'] == facility_id]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "aux_facility_daily_df = (\n",
    "    aux_daily_df[aux_daily_df['unique_id'] == facility_id]\n",
    "    .copy()\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "facility_daily_df = heat_facility_daily_df.merge(\n",
    "    aux_facility_daily_df,\n",
    "    on=['ds', 'unique_id'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Select numeric columns\n",
    "df_for_plot = facility_daily_df.select_dtypes(include='number').copy()\n",
    "cols = df_for_plot.columns.tolist()\n",
    "n = len(cols)\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=n,\n",
    "    cols=n,\n",
    "    shared_xaxes=False,\n",
    "    shared_yaxes=False,\n",
    "    horizontal_spacing=0.01,\n",
    "    vertical_spacing=0.01,    \n",
    ")\n",
    "\n",
    "for i, row_col in enumerate(cols):\n",
    "    for j, col_col in enumerate(cols):\n",
    "        x = df_for_plot[col_col]\n",
    "        y = df_for_plot[row_col]\n",
    "\n",
    "        # Diagonal: histogram (like sns.histplot on the diagonal)\n",
    "        if i == j:\n",
    "            fig.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=x,\n",
    "                    nbinsx=30,\n",
    "                    showlegend=False,\n",
    "                    marker=dict(color='black', opacity=0.7)\n",
    "                ),\n",
    "                row=i + 1,\n",
    "                col=j + 1\n",
    "            )\n",
    "\n",
    "        # Lower triangle: scatter + linear trend + LOWESS (scatter_with_trend)\n",
    "        elif i > j:\n",
    "            # Remove NaNs\n",
    "            valid = x.notna() & y.notna()\n",
    "            x_valid = x[valid]\n",
    "            y_valid = y[valid]\n",
    "\n",
    "            # Scatter\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_valid,\n",
    "                    y=y_valid,\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=4, opacity=0.4, color='black'),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=i + 1,\n",
    "                col=j + 1\n",
    "            )\n",
    "\n",
    "            # LOWESS smoother (like your red dashed line)\n",
    "            if len(x_valid) > 5:\n",
    "                lowess_res = lowess(y_valid, x_valid, frac=0.3, return_sorted=True)\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=lowess_res[:, 0],\n",
    "                        y=lowess_res[:, 1],\n",
    "                        mode='lines',\n",
    "                        line=dict(width=3, color=\"#ff0000\"),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=i + 1,\n",
    "                    col=j + 1\n",
    "                )\n",
    "\n",
    "            # Linear trend (OLS)\n",
    "            if len(x_valid) > 1:\n",
    "                m, b = np.polyfit(x_valid, y_valid, 1)\n",
    "                xs = np.linspace(x_valid.min(), x_valid.max(), 50)\n",
    "                ys = m * xs + b\n",
    "\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(\n",
    "                        x=xs,\n",
    "                        y=ys,\n",
    "                        mode='lines',\n",
    "                        line=dict(width=3, dash='dot', color=\"#22ff00\"),\n",
    "                        showlegend=False\n",
    "                    ),\n",
    "                    row=i + 1,\n",
    "                    col=j + 1\n",
    "                )\n",
    "\n",
    "        # Upper triangle: correlation text (corrfunc)\n",
    "        else:  # i < j\n",
    "            pair = df_for_plot[[col_col, row_col]].dropna()\n",
    "            if len(pair) > 1:\n",
    "                pearson_r, _ = pearsonr(pair[col_col], pair[row_col])\n",
    "                spearman_r, _ = spearmanr(pair[col_col], pair[row_col])\n",
    "                kendall_r, _ = kendalltau(pair[col_col], pair[row_col])\n",
    "                text = (\n",
    "                    f\"S: {spearman_r:.2f}<br>\"\n",
    "                    f\"P: {pearson_r:.2f}<br>\"\n",
    "                )\n",
    "            else:\n",
    "                text = \"n/a\"\n",
    "\n",
    "            # Position the text in the middle of the cell\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[0.5],\n",
    "                    y=[0.4],\n",
    "                    text=[text],\n",
    "                    mode='text',\n",
    "                    showlegend=False,\n",
    "                    textfont=dict(size=14), \n",
    "                ),\n",
    "                row=i + 1,\n",
    "                col=j + 1\n",
    "            )\n",
    "\n",
    "            # Make this panel look like a label panel, not a real axis\n",
    "            fig.update_xaxes(\n",
    "                showgrid=False,\n",
    "                showticklabels=False,\n",
    "                range=[0, 1],\n",
    "                row=i + 1,\n",
    "                col=j + 1\n",
    "            )\n",
    "            fig.update_yaxes(\n",
    "                showgrid=False,\n",
    "                showticklabels=False,\n",
    "                range=[0, 1],\n",
    "                row=i + 1,\n",
    "                col=j + 1\n",
    "            )\n",
    "\n",
    "# Hide all tick labels\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        fig.update_xaxes(\n",
    "            showticklabels=False, row=i+1, col=j+1,\n",
    "            showline=True,\n",
    "            linewidth=1,\n",
    "            linecolor=\"lightgrey\",\n",
    "            mirror=True,\n",
    "        )\n",
    "        fig.update_yaxes(\n",
    "            showticklabels=False, row=i+1, col=j+1,\n",
    "            showline=True,\n",
    "            linewidth=1,\n",
    "            linecolor=\"lightgrey\",\n",
    "            mirror=True,\n",
    "        )\n",
    "\n",
    "nice_names = {\n",
    "    'dew_point': 'DPT (°C)',\n",
    "    'temperature': 'T (°C)',\n",
    "    'wind_speed': 'WS (m/s)',\n",
    "    'pressure': 'P (hPa)',\n",
    "    'humidity': 'RH (%)',\n",
    "    'y': 'Q (kWh)'\n",
    "}\n",
    "    \n",
    "# Show x labels only on the bottom row\n",
    "for j, col_name in enumerate(cols):\n",
    "    fig.update_xaxes(\n",
    "        showticklabels=True,\n",
    "        title_text=\"\",\n",
    "        row=n,\n",
    "        col=j+1\n",
    "    )\n",
    "\n",
    "# Show y labels only on the first column\n",
    "for i, row_name in enumerate(cols):\n",
    "    fig.update_yaxes(\n",
    "        showticklabels=True,\n",
    "        title_text=\"\",\n",
    "        row=i+1,\n",
    "        col=1,\n",
    "        title_standoff=50\n",
    "    )\n",
    "\n",
    "for i, row_name in enumerate(cols):\n",
    "    fig.add_annotation(\n",
    "        x=0,               \n",
    "        y=0.5,              \n",
    "        xref='x domain',\n",
    "        yref='y domain',\n",
    "        text=nice_names.get(row_name, row_name),\n",
    "        showarrow=False,\n",
    "        textangle=-90,\n",
    "        xanchor='center',\n",
    "        yanchor='middle',\n",
    "        font=dict(size=14),\n",
    "        xshift=-45,         \n",
    "        row=i + 1,\n",
    "        col=1\n",
    "    )\n",
    "for i, col_name in enumerate(cols):\n",
    "    fig.add_annotation(\n",
    "        x=0.5,               \n",
    "        y=0,              \n",
    "        xref='x domain',\n",
    "        yref='y domain',\n",
    "        text=nice_names.get(col_name, col_name),\n",
    "        showarrow=False,\n",
    "        textangle=0,\n",
    "        xanchor='center',\n",
    "        yanchor='middle',\n",
    "        font=dict(size=14),\n",
    "        yshift=-45,         \n",
    "        row=len(cols),\n",
    "        col=i + 1\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=None,\n",
    "    height=800,\n",
    "    width=800,\n",
    "    bargap=0.1,\n",
    "    hovermode='closest',\n",
    "    template='plotly_white',\n",
    "    margin=dict(l=10, r=10, t=10, b=60),\n",
    ")\n",
    "pio.write_html(\n",
    "    fig, \"fig.html\",\n",
    "    include_plotlyjs=\"inline\", full_html=True,\n",
    "    config={\"toImageButtonOptions\": {\"format\": \"png\", \"scale\": 2}}\n",
    ")\n",
    "fig\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
